name: fidel-ai

services:
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu
    env_file: .env
    environment:
      # Ensure CORS allows the WebUI origin
      - ALLOW_ORIGINS=http://localhost:2345
    ports:
      - "8080:8080"
    networks: [appnet]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 5

    # For CUDA build
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia

  webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "2345:2345"   # Web UI available at http://localhost:2345
    environment:
      # Wire Open WebUI to your API (OpenAI-compatible)
      - OPENAI_API_BASE_URL=http://api:8080/v1
      - OPENAI_API_KEY=dev-key  # your API may ignore this, but WebUI expects a key
      # Optional: auto-create a connection on first run
      - WEBUI_NAME=FidelAI
    volumes:
      - webui_data:/app/backend/data
    networks: [appnet]

networks:
  appnet: {}

volumes:
  webui_data: {}
